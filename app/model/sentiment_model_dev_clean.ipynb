{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./data/Task-2/train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(text, stem=\"None\"):\n",
    "\n",
    "    final_string = \"\"\n",
    "\n",
    "    # Make lower\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove line breaks\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "\n",
    "    # Remove puncuation\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "\n",
    "    # Remove stop words\n",
    "    text = text.split()\n",
    "    useless_words = nltk.corpus.stopwords.words(\"english\")\n",
    "    useless_words = useless_words + ['hi', 'im']\n",
    "\n",
    "    text_filtered = [word for word in text if not word in useless_words]\n",
    "\n",
    "    # Remove numbers\n",
    "    text_filtered = [re.sub(r'\\w*\\d\\w*', '', w) for w in text_filtered]\n",
    "\n",
    "    # Stem or Lemmatize\n",
    "    if stem == 'Stem':\n",
    "        stemmer = PorterStemmer() \n",
    "        text_stemmed = [stemmer.stem(y) for y in text_filtered]\n",
    "    elif stem == 'Lem':\n",
    "        lem = WordNetLemmatizer()\n",
    "        text_stemmed = [lem.lemmatize(y) for y in text_filtered]\n",
    "    elif stem == 'Spacy':\n",
    "        nlp = spacy.load('en_core_web_sm')\n",
    "        text_filtered = nlp(' '.join(text_filtered))\n",
    "        text_stemmed = [y.lemma_ for y in text_filtered]\n",
    "    else:\n",
    "        text_stemmed = text_filtered\n",
    "\n",
    "    final_string = ' '.join(text_stemmed)\n",
    "\n",
    "    return final_string\n",
    "\n",
    "def clean_pandas(df, colunm_name='text', stem=\"Stem\"):\n",
    "    df[colunm_name] = df[colunm_name].apply(lambda x: clean_string(x, stem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./data/Task-2/train.xlsx')\n",
    "# clean\n",
    "df = clean_pandas(df, colunm_name='text', stem=\"Stem\")\n",
    "df.to_excel('./data/Task-2/train_processed_stem.xlsx', columns=['text','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: clean_string(x, stem='Stem'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('./data/Task-2/train_processed_stem.xlsx', columns=['text','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fiskar strong portfolio intern brand includ fi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metalszinc surg pct glencor cut output fuell m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accord scanfil demand telecommun network produ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>db launch new bank api develop platform india ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theodosopoulo say tellab could valu nokia siem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4333</th>\n",
       "      <td>airvana umt home base station femto cell use s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334</th>\n",
       "      <td>malton net profit jump four time gain revok deal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4335</th>\n",
       "      <td>accord ceo kai telann compani newspap achiev g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336</th>\n",
       "      <td>addit cramo peab sign exclus fiveyear rental a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4337</th>\n",
       "      <td>ntc geograph presenc complement ramir exist ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4338 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     fiskar strong portfolio intern brand includ fi...      1\n",
       "1     metalszinc surg pct glencor cut output fuell m...      1\n",
       "2     accord scanfil demand telecommun network produ...     -1\n",
       "3     db launch new bank api develop platform india ...      1\n",
       "4     theodosopoulo say tellab could valu nokia siem...      1\n",
       "...                                                 ...    ...\n",
       "4333  airvana umt home base station femto cell use s...      1\n",
       "4334   malton net profit jump four time gain revok deal      1\n",
       "4335  accord ceo kai telann compani newspap achiev g...      1\n",
       "4336  addit cramo peab sign exclus fiveyear rental a...      1\n",
       "4337  ntc geograph presenc complement ramir exist ne...      1\n",
       "\n",
       "[4338 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import spacy\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CleanText(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, stem=\"None\"):\n",
    "        self.stem = stem\n",
    "\n",
    "    def clean_string(self, text):\n",
    "        final_string = \"\"\n",
    "\n",
    "        # Make lower\n",
    "        text = text.lower()\n",
    "\n",
    "        # Remove line breaks\n",
    "        text = re.sub(r'\\n', '', text)\n",
    "\n",
    "        # Remove puncuation\n",
    "        translator = str.maketrans('', '', string.punctuation)\n",
    "        text = text.translate(translator)\n",
    "\n",
    "        # Remove stop words\n",
    "        text = text.split()\n",
    "        useless_words = nltk.corpus.stopwords.words(\"english\")\n",
    "        useless_words = useless_words + ['hi', 'im']\n",
    "\n",
    "        text_filtered = [word for word in text if not word in useless_words]\n",
    "\n",
    "        # Remove numbers\n",
    "        text_filtered = [re.sub(r'\\w*\\d\\w*', '', w) for w in text_filtered]\n",
    "\n",
    "        # Stem or Lemmatize\n",
    "        if self.stem == 'Stem':\n",
    "            stemmer = PorterStemmer() \n",
    "            text_stemmed = [stemmer.stem(y) for y in text_filtered]\n",
    "        elif self.stem == 'Lem':\n",
    "            lem = WordNetLemmatizer()\n",
    "            text_stemmed = [lem.lemmatize(y) for y in text_filtered]\n",
    "        elif self.stem == 'Spacy':\n",
    "            nlp = spacy.load('en_core_web_sm')\n",
    "            text_filtered = nlp(' '.join(text_filtered))\n",
    "            text_stemmed = [y.lemma_ for y in text_filtered]\n",
    "        else:\n",
    "            text_stemmed = text_filtered\n",
    "\n",
    "        final_string = ' '.join(text_stemmed)\n",
    "\n",
    "        return final_string\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_cleaned = [self.clean_string(text) for text in X]\n",
    "        return X_cleaned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
